

# MSE LOSS


# For 0.6 | 1 
# Best Pearson Correlation: 0.7870 at epoch 87
# Best Accuracy: 0.7011 at epoch 95
# Epochs where Pearson >= 0.77 and Accuracy >= 0.69: [112]

# For 0.5 | 0.9
# Best Pearson Correlation: 0.7907 at epoch 109
# Best Accuracy: 0.7011 at epoch 80
# Epochs where Pearson >= 0.77 and Accuracy >= 0.69: [112, 116]

# For 0.9 | 1.4
# Best Pearson Correlation: 0.7766 at epoch 53
# Best Accuracy: 0.7116 at epoch 66
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.4 | 0.8
# Best Pearson Correlation: 0.7956 at epoch 109
# Best Accuracy: 0.6984 at epoch 100
# Epochs where Pearson >= 0.77 and Accuracy >= 0.69: [126]


# For 0.55 | 0.9
# Best Pearson Correlation: 0.7898 at epoch 109
# Best Accuracy: 0.7063 at epoch 80
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.5 | 0.6
# Best Pearson Correlation: 0.7896 at epoch 91
# Best Accuracy: 0.6984 at epoch 80
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.9 | 1.2
# Best Pearson Correlation: 0.7753 at epoch 69
# Best Accuracy: 0.7037 at epoch 125
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.7 | 0.5
# Best Pearson Correlation: 0.7832 at epoch 87
# Best Accuracy: 0.6905 at epoch 139
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.6 | 0.4
# Best Pearson Correlation: 0.7873 at epoch 91
# Best Accuracy: 0.6905 at epoch 139
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 1.2 | 1.5
# Best Pearson Correlation: 0.7764 at epoch 44
# Best Accuracy: 0.7011 at epoch 60
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.4 | 0.6
# Best Pearson Correlation: 0.7967 at epoch 109
# Best Accuracy: 0.6878 at epoch 124
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.5 | 0.8
# Best Pearson Correlation: 0.7937 at epoch 109
# Best Accuracy: 0.7011 at epoch 80
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.


# For 0.5 | 0.5
Best Pearson Correlation: 0.7910 at epoch 109
Best Accuracy: 0.6852 at epoch 94
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.7 | 1.3
Best Pearson Correlation: 0.7767 at epoch 87
Best Accuracy: 0.7143 at epoch 134
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.6 | 1.1
Best Pearson Correlation: 0.7859 at epoch 73
Best Accuracy: 0.7116 at epoch 130
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.55 | 0.75
Best Pearson Correlation: 0.7905 at epoch 109
Best Accuracy: 0.6984 at epoch 80
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.8 | 0.6
Best Pearson Correlation: 0.7905 at epoch 109
Best Accuracy: 0.6984 at epoch 80
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.


For 0.3 | 0.6 
Best Pearson Correlation: 0.7923 at epoch 138
Best Accuracy: 0.6931 at epoch 31
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

For 0.7 | 0.9
Best Pearson Correlation: 0.7840 at epoch 73
Best Accuracy: 0.7037 at epoch 80
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

For 0.9 | 0.5
Best Pearson Correlation: 0.7795 at epoch 54
Best Accuracy: 0.6825 at epoch 132
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

For 0.4 | 0.7
Best Pearson Correlation: 0.7970 at epoch 109
Best Accuracy: 0.6931 at epoch 132
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.




# For 0.4 | 0.6 MEANABSOLUTEERROR LOSS
# Best Pearson Correlation: 0.7908 at epoch 153
# Best Accuracy: 0.6799 at epoch 77
# No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.


# For 0.4 | 0.7 MEANABSOLUTEERROR LOSS
Best Pearson Correlation: 0.7630 at epoch 153
Best Accuracy: 0.7090 at epoch 139
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 1 | 0.7 MEANABSOLUTEERROR LOSS
Best Pearson Correlation: 0.7911 at epoch 97
Best Accuracy: 0.6958 at epoch 100
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met

# For 1.2 | 0.7 MEANABSOLUTEERROR LOSS
Best Pearson Correlation: 0.7783 at epoch 84
Best Accuracy: 0.6984 at epoch 104
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.5 | 0.5 MEANABSOLUTEERROR LOSS
Best Pearson Correlation: 0.7821 at epoch 153
Second Best Accuracy: 0.7037 at epoch 135
Best Accuracy: 0.7063 at epoch 154
Epochs where Pearson >= 0.77 and Accuracy >= 0.69: [136, 137, 140, 154, 166, 181, 198]


---------------------------------------- CLASS MODELS ----------------------------------------

# For 0.5 | 0.5 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Best Pearson Correlation: 0.7846 at epoch 177
Best Accuracy: 0.7063 at epoch 127
Epochs where Pearson >= 0.77 and Accuracy >= 0.69: [138, 149, 152, 154, 155, 160, 166]


# Best weights for lowest Validation Loss: {'rating_model': 0.1, 'comparison_model': 0.9}, Validation Loss: 0.7077, Epochs: 93 -> abysmal
# Best weights for lowest Validation Rating Model Loss: {'rating_model': 0.8, 'comparison_model': 0.2}, Validation Rating Model Loss: 0.7073, Epochs: 98 -> not good
# Best weights for lowest Validation Comparison Model Loss: {'rating_model': 0.2, 'comparison_model': 0.8}, Validation Comparison Model Loss: 0.5963, Epochs: 169 -> not bad , for 156 or 143 epochs,  pearson = 0.78


# For 0.6 | 0.4 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Best Pearson Correlation: 0.7848 at epoch 154
Best Accuracy: 0.6958 at epoch 176
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.4 | 0.6 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Best Pearson Correlation: 0.7713 at epoch 175
Best Accuracy: 0.7063 at epoch 137
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.

# For 0.5 | 0.6 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Best Pearson Correlation: 0.7798 at epoch 153
Best Accuracy: 0.7063 at epoch 122
Epochs where Pearson >= 0.77 and Accuracy >= 0.69: [137]










# For 0.6 | 0.5 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Best Pearson Correlation: 0.5057 at epoch 194
Best Accuracy: 0.5847 at epoch 199
No epochs where both Pearson >= 0.77 and Accuracy >= 0.69 were met.



# For 0.7 | 0.3 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Summary for Weight Combination - Rating: 0.7, Comparison: 0.3
Best Pearson Correlation: 0.5032 at epoch 194
Best Accuracy: 0.6164 at epoch 189
No epochs met both thresholds.


# For 0.3 | 0.7 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Summary for Weight Combination - Rating: 0.3, Comparison: 0.7
Best Pearson Correlation: -0.1392 at epoch 199
Best Accuracy: 0.6217 at epoch 54
No epochs met both thresholds.


# For 0.8 | 0.2 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Summary for Weight Combination - Rating: 0.8, Comparison: 0.2
Best Pearson Correlation: 0.4923 at epoch 192
Best Accuracy: 0.5661 at epoch 200
No epochs met both thresholds.


# For 0.2 | 0.8 MEANABSOLUTEERROR LOSS AND CLASS MODELS
Summary for Weight Combination - Rating: 0.2, Comparison: 0.8
Best Pearson Correlation: -0.2639 at epoch 200
Best Accuracy: 0.6323 at epoch 200
No epochs met both thresholds.



Training with rating_model weight: 0.4, comparison_model weight: 0.7
Summary for Weight Combination - Rating: 0.4, Comparison: 0.7
Best Pearson Correlation: 0.4351 at epoch 198
Best Accuracy: 0.6111 at epoch 51
No epochs met both thresholds.


Training with rating_model weight: 0.5, comparison_model weight: 0.7
Summary for Weight Combination - Rating: 0.5, Comparison: 0.7
Best Pearson Correlation: 0.4671 at epoch 188
Best Accuracy: 0.6640 at epoch 200
No epochs met both thresholds.


Training with rating_model weight: 0.4, comparison_model weight: 0.6
Summary for Weight Combination - Rating: 0.4, Comparison: 0.6
Best Pearson Correlation: 0.4138 at epoch 200
Best Accuracy: 0.6164 at epoch 51
No epochs met both thresholds.


Training with rating_model weight: 0.6, comparison_model weight: 0.5
Summary for Weight Combination - Rating: 0.6, Comparison: 0.5
Best Pearson Correlation: 0.5078 at epoch 196
Best Accuracy: 0.5741 at epoch 52
No epochs met both thresholds.

Summary for Weight Combination - Rating: 0.6, Comparison: 0.7
Best Pearson Correlation: 0.4944 at epoch 196
Best Accuracy: 0.6455 at epoch 199
No epochs met both thresholds.



Training with rating_model weight: 0.7, comparison_model weight: 0.7
Summary for Weight Combination - Rating: 0.7, Comparison: 0.7
Best Pearson Correlation: 0.5017 at epoch 194
Best Accuracy: 0.6323 at epoch 179
No epochs met both thresholds.


Training with rating_model weight: 0.7, comparison_model weight: 0.8
Summary for Weight Combination - Rating: 0.7, Comparison: 0.8
Best Pearson Correlation: 0.4952 at epoch 197
Best Accuracy: 0.6296 at epoch 190
No epochs met both thresholds.


Training with rating_model weight: 0.8, comparison_model weight: 0.7
Summary for Weight Combination - Rating: 0.8, Comparison: 0.7
Best Pearson Correlation: 0.4836 at epoch 196
Best Accuracy: 0.6270 at epoch 192
No epochs met both thresholds.


Training with rating_model weight: 0.8, comparison_model weight: 1
Summary for Weight Combination - Rating: 0.8, Comparison: 1
Best Pearson Correlation: 0.4985 at epoch 186
Best Accuracy: 0.6905 at epoch 196
No epochs met both thresholds.


Training with rating_model weight: 0.8, comparison_model weight: 0.9
Summary for Weight Combination - Rating: 0.8, Comparison: 0.9
Best Pearson Correlation: 0.5130 at epoch 174
Best Accuracy: 0.6481 at epoch 191
No epochs met both thresholds.


Training with rating_model weight: 0.1, comparison_model weight: 0.1
Summary for Weight Combination - Rating: 0.1, Comparison: 0.1
Best Pearson Correlation: -0.2829 at epoch 51
Best Accuracy: 0.6217 at epoch 115
No epochs met both thresholds.


Training with rating_model weight: 0.1, comparison_model weight: 0.2
Summary for Weight Combination - Rating: 0.1, Comparison: 0.2
Best Pearson Correlation: -0.2308 at epoch 51
Best Accuracy: 0.6429 at epoch 96
No epochs met both thresholds.





Training with rating_model weight: 0.4, comparison_model weight: 0.5

Summary for Weight Combination - Rating: 0.4, Comparison: 0.5
Best Pearson Correlation: 0.4622 at epoch 196
Best Accuracy: 0.6111 at epoch 51
No epochs met both thresholds.


Training with rating_model weight: 0.7, comparison_model weight: 0.4

Summary for Weight Combination - Rating: 0.7, Comparison: 0.4
Best Pearson Correlation: 0.5156 at epoch 197
Best Accuracy: 0.5847 at epoch 198
No epochs met both thresholds.


Training with rating_model weight: 0.7, comparison_model weight: 0.6

Summary for Weight Combination - Rating: 0.7, Comparison: 0.6
Best Pearson Correlation: 0.4937 at epoch 193
Best Accuracy: 0.6032 at epoch 193
No epochs met both thresholds.


Training with rating_model weight: 0.7, comparison_model weight: 0.7

Summary for Weight Combination - Rating: 0.7, Comparison: 0.7
Best Pearson Correlation: 0.5197 at epoch 175
Best Accuracy: 0.5847 at epoch 192
No epochs met both thresholds.


Training with rating_model weight: 0.7, comparison_model weight: 0.8

Summary for Weight Combination - Rating: 0.7, Comparison: 0.8
Best Pearson Correlation: 0.5037 at epoch 192
Best Accuracy: 0.6402 at epoch 199
No epochs met both thresholds.


Training with rating_model weight: 0.7, comparison_model weight: 1

Summary for Weight Combination - Rating: 0.7, Comparison: 1
Best Pearson Correlation: 0.4622 at epoch 145
Best Accuracy: 0.6825 at epoch 193
No epochs met both thresholds.






Summary for Weight Combination - Rating: 0.5, Comparison: 0.5

Epoch 128: Pearson = 0.7757179662653761, Accuracy = 0.6904761791229248
Epoch 130: Pearson = 0.7714648529139284, Accuracy = 0.7010582089424133
Epoch 133: Pearson = 0.7717215356518249, Accuracy = 0.7010582089424133
Epoch 136: Pearson = 0.7797325761845725, Accuracy = 0.6931216716766357
Epoch 137: Pearson = 0.7791288493259727, Accuracy = 0.6957672238349915
Epoch 138: Pearson = 0.7776386080939713, Accuracy = 0.6957672238349915
Epoch 140: Pearson = 0.7825357110577293, Accuracy = 0.6931216716766357
Epoch 141: Pearson = 0.7832664758148196, Accuracy = 0.6904761791229248
Epoch 142: Pearson = 0.781108088064889, Accuracy = 0.6931216716766357
Epoch 143: Pearson = 0.7741963429960037, Accuracy = 0.6904761791229248
Epoch 146: Pearson = 0.7765596631855045, Accuracy = 0.6957672238349915
Epoch 147: Pearson = 0.7724066722622048, Accuracy = 0.6957672238349915


Epoch 138: Pearson = 0.7704844556250837, Accuracy = 0.6904761791229248
Epoch 167: Pearson = 0.7799668411120481, Accuracy = 0.6904761791229248
Epoch 170: Pearson = 0.7713371335684888, Accuracy = 0.6904761791229248
Epoch 171: Pearson = 0.7771361477268799, Accuracy = 0.6957672238349915
Epoch 172: Pearson = 0.7745480993308995, Accuracy = 0.6904761791229248
Epoch 187: Pearson = 0.7760089425860934, Accuracy = 0.6904761791229248

Summary for Weight Combination - Rating: 0.5, Comparison: 0.5
Best Pearson Correlation: 0.7889 at epoch 177
Best Accuracy: 0.7037 at epoch 125
Epochs meeting thresholds: [138, 167, 170, 171, 172, 187]




Epoch 120: Pearson = 0.7717395851671981, Accuracy = 0.6984127163887024
Epoch 128: Pearson = 0.7739169600842377, Accuracy = 0.6984127163887024
Epoch 136: Pearson = 0.7760191044986491, Accuracy = 0.6957672238349915
Epoch 137: Pearson = 0.7754525907445189, Accuracy = 0.6984127163887024
Epoch 138: Pearson = 0.7774131238426816, Accuracy = 0.6904761791229248
Epoch 140: Pearson = 0.7820033661096434, Accuracy = 0.6931216716766357
Epoch 141: Pearson = 0.7828746439929627, Accuracy = 0.6984127163887024
Epoch 142: Pearson = 0.7818130456347387, Accuracy = 0.6931216716766357

Summary for Weight Combination - Rating: 0.5, Comparison: 0.5
Best Pearson Correlation: 0.7834 at epoch 154
Best Accuracy: 0.7011 at epoch 122
Epochs meeting thresholds pearson >= 0.77 and accuracy >= 0.69: [120, 128, 136, 137, 138, 140, 141, 142]


























-----------------------------------------------GRID SEARCH-----------------------------------------------


# from scipy import stats
# from math import sqrt
# # Your normalization and evaluation functions
# def normalize_image_pairs(X_pairs):
#     normalized_pairs = []
#     for img1, img2 in X_pairs:
#         img1_normalized = img1 / 255.0
#         img2_normalized = img2 / 255.0
#         normalized_pairs.append((img1_normalized, img2_normalized))
#     return normalized_pairs

# def pearsonr_ci(x, y, alpha=0.05):
#     N = len(x)
#     r, p = stats.pearsonr(x, y)
#     r_z = np.arctanh(r)
#     se = 1/np.sqrt(N-3)
#     z = stats.norm.ppf(1-alpha/2)
#     lo_z, hi_z = r_z-z*se, r_z+z*se
#     lo, hi = np.tanh((lo_z, hi_z))
#     return r, p, lo, hi 

# def train_and_evaluate(alpha, beta):
#     # Register the custom loss functions and metrics
#     get_custom_objects().update({
#         'mse_regression_loss': mse_regression_loss,
#         'bradley_terry_loss': bradley_terry_loss,
#         'rating_rmse': rating_rmse,
#         'custom_binary_accuracy': custom_binary_accuracy
#     })

#     # Set up the optimizer and compile the model
#     sgd = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True)
    
#     joint_model.compile(
#         optimizer=sgd, 
#         loss={
#             'rating_model': 'mse_regression_loss', 
#             'comparison_model': 'bradley_terry_loss'
#         },
#         loss_weights={
#             'rating_model': alpha,  # Weight for rating loss
#             'comparison_model': beta   # Weight for comparison loss
#         },  
#         metrics={
#             'rating_model': 'rating_rmse', 
#             'comparison_model': 'custom_binary_accuracy'
#         }
#     )

#     # Train the joint model
#     joint_model.fit(
#         train_generator,
#         validation_data=val_generator,
#         epochs=epochs
#     )

    # # Evaluation
    # rating_predictions = []
    # X_val_norm = X_val / 255.0
    # for img in X_val_norm:
    #     img = img.reshape(1, 192, 256, 3)
    #     pred = rating_model.predict(img)
    #     rating_predictions.append(float(pred))
    # rating_predictions = np.array(rating_predictions)

    # corr, p, lo, hi = pearsonr_ci(y_val, rating_predictions)
    # rmse_test = sqrt(np.mean(np.square(y_val - rating_predictions)))

    # X_pairs_val_normalized = normalize_image_pairs(X_pairs_val)
    # comparison_predictions = []
    # for img1, img2 in X_pairs_val_normalized:
    #     img1_norm = np.expand_dims(img1, axis=0)
    #     img2_norm = np.expand_dims(img2, axis=0)
    #     pred = comparison_model.predict([img1_norm, img2_norm])
    #     comparison_predictions.append(float(pred[0][0]))
    # comparison_predictions = np.array(comparison_predictions)
    # comparison_accuracy = custom_binary_accuracy(y_pairs_val, comparison_predictions).numpy()

    # return corr, comparison_accuracy, joint_model

# # Grid search over alpha
# best_corr = -np.inf
# best_accuracy = -np.inf
# best_alpha = None
# best_beta = None
# best_model = None

# # alpha with Comparison Accuracy >= 0.69: 0.04081632653061224 Pearson Correlation: 0.5489 Comparison Accuracy: 0.7011
# # alpha, beta with Pearson Correlation >= 0.78: 0.4444444444444444, 0.4444444444444444 Pearson Correlation: 0.7847 Comparison Accuracy: 0.6693
# # alpha, beta with Comparison Accuracy >= 0.69: 1.0000000000000002, 0.8888888888888891 Pearson Correlation: 0.6923 Comparison Accuracy: 0.7063

# # Define the threshold values
# pearson_threshold = 0.78
# accuracy_threshold = 0.69

# # alpha_values = np.linspace(0, 1, 10)  # Adjust the range and number of values as needed
# # beta_values = np.linspace(0, 1, 10)  # Adjust the range and number of values as needed
# # Define the starting point and step size

# # alpha: 1.7, beta: 0.425, Pearson Correlation: 0.6996, Comparison Accuracy: 0.6667

# start_alpha = 0.3
# start_beta = 0.3
# step_size = 1 / (10 - 4)  
# # Generate new alpha and beta values starting from the given point
# alpha_values = np.arange(start_alpha, 1 + step_size, step_size)
# beta_values = np.arange(start_beta, 1.3 + step_size, step_size)

# for alpha in alpha_values:
#     for beta in beta_values:
#         corr, accuracy, model = train_and_evaluate(alpha, beta)
#         print(f"alpha: {alpha}, beta: {beta}, Pearson Correlation: {corr:.4f}, Comparison Accuracy: {accuracy:.4f}")
        
#         if corr >= pearson_threshold:
#             print(f"\nalpha, beta with Pearson Correlation >= {pearson_threshold}: {alpha}, {beta}")
#             print(f"Pearson Correlation: {corr:.4f}")
#             print(f"Comparison Accuracy: {accuracy:.4f}")
        
#         if accuracy >= accuracy_threshold:
#             print(f"\nalpha, beta with Comparison Accuracy >= {accuracy_threshold}: {alpha}, {beta}")
#             print(f"Pearson Correlation: {corr:.4f}")
#             print(f"Comparison Accuracy: {accuracy:.4f}")

#         if corr > best_corr and accuracy > best_accuracy:
#             best_corr = corr
#             best_accuracy = accuracy
#             best_alpha = alpha
#             best_beta = beta
#             best_model = model

# print(f"Best alpha: {best_alpha}, Best beta: {best_beta}, Best Pearson Correlation: {best_corr}, Best Comparison Accuracy: {best_accuracy}")






from scipy import stats
from math import sqrt

# # Define weight combinations for grid search
# weight_combinations = [
#     {'rating_model': 0.1, 'comparison_model': 0.9},
#     {'rating_model': 0.2, 'comparison_model': 0.8},
#     {'rating_model': 0.3, 'comparison_model': 0.7},
#     {'rating_model': 0.4, 'comparison_model': 0.6},
#     {'rating_model': 0.5, 'comparison_model': 0.5},
#     {'rating_model': 0.6, 'comparison_model': 0.4},
#     {'rating_model': 0.7, 'comparison_model': 0.3},
#     {'rating_model': 0.8, 'comparison_model': 0.2},
#     {'rating_model': 0.9, 'comparison_model': 0.1}

    # {'rating_model': 1.0, 'comparison_model': 1.0},
    # {'rating_model': 0.5, 'comparison_model': 1.0},
    # {'rating_model': 1.0, 'comparison_model': 0.5},
    # {'rating_model': 0.3, 'comparison_model': 1.2},
    # {'rating_model': 1.2, 'comparison_model': 0.3},
    # {'rating_model': 0.7, 'comparison_model': 0.7},
    # {'rating_model': 0.2, 'comparison_model': 1.5},
    # {'rating_model': 1.5, 'comparison_model': 0.2},
    # {'rating_model': 0.4, 'comparison_model': 1.3},
    # {'rating_model': 1.3, 'comparison_model': 0.4},
    # {'rating_model': 0.6, 'comparison_model': 1.0},
    # {'rating_model': 1.0, 'comparison_model': 0.6},
    # {'rating_model': 0.8, 'comparison_model': 1.0},
    # {'rating_model': 1.0, 'comparison_model': 0.8},
    # {'rating_model': 0.9, 'comparison_model': 1.2},
    # {'rating_model': 1.2, 'comparison_model': 0.9}


    # {'rating_model': 0.6, 'comparison_model': 1.2},
    # {'rating_model': 1.2, 'comparison_model': 0.6},
    # {'rating_model': 0.7, 'comparison_model': 1.3},
    # {'rating_model': 1.3, 'comparison_model': 0.7},
    # {'rating_model': 0.8, 'comparison_model': 1.1},
    # {'rating_model': 1.1, 'comparison_model': 0.8},
    # {'rating_model': 0.9, 'comparison_model': 1.4},
    # {'rating_model': 1.4, 'comparison_model': 0.9},
    # {'rating_model': 0.7, 'comparison_model': 1.0},
    # {'rating_model': 1.0, 'comparison_model': 0.7}
# ]


# # Define a new range of weight combinations for grid search
# weight_combinations = [
#     {'rating_model': 0.2, 'comparison_model': 2.0},
#     {'rating_model': 2.0, 'comparison_model': 0.2},
#     {'rating_model': 0.4, 'comparison_model': 1.8},
#     {'rating_model': 1.8, 'comparison_model': 0.4},
#     {'rating_model': 0.6, 'comparison_model': 1.5},
#     {'rating_model': 1.5, 'comparison_model': 0.6},
#     {'rating_model': 0.3, 'comparison_model': 1.9},
#     {'rating_model': 1.9, 'comparison_model': 0.3},
#     {'rating_model': 0.5, 'comparison_model': 1.7},
#     {'rating_model': 1.7, 'comparison_model': 0.5}
# ]

# # Define the threshold values
# pearson_threshold = 0.78
# accuracy_threshold = 0.69

# # Variables to track the best results
# best_val_loss = np.inf
# best_val_rating_model_loss = np.inf
# best_val_comparison_model_loss = np.inf

# best_weights_val_loss = None
# best_weights_val_rating_model_loss = None
# best_weights_val_comparison_model_loss = None

# best_epochs_val_loss = 0
# best_epochs_val_rating_model_loss = 0
# best_epochs_val_comparison_model_loss = 0

# # Store results
# results = []

# # Early stopping callback
# early_stopping = callbacks.EarlyStopping(
#     monitor='val_loss', 
#     patience=10, 
#     restore_best_weights=True
# )


# # Loop through each weight combination
# for weights in weight_combinations:
#     print(f"Training with weights: {weights}")
    
#     # Reinitialize the models
#     shared_feature_extractor = create_shared_feature_extractor()
#     rating_model = create_ratingModel(shared_feature_extractor)
#     comparison_model = create_comparisonModel(shared_feature_extractor)

#     rating_input = layers.Input(shape=(192, 256, 3), name='rating_input')
#     comparison_input_a = layers.Input(shape=(192, 256, 3), name='comparison_input_a')
#     comparison_input_b = layers.Input(shape=(192, 256, 3), name='comparison_input_b')

#     # Define outputs for joint model
#     rating_output = rating_model(rating_input)
#     comparison_output = comparison_model([comparison_input_a, comparison_input_b])

#     joint_model = models.Model(
#         inputs=[rating_input, comparison_input_a, comparison_input_b],
#         outputs=[rating_output, comparison_output],
#         name='joint_model'
#     )
    
#     # Compile the model with the current weight combination
#     joint_model.compile(
#         optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
#         loss={
#             'rating_model': 'mse_regression_loss',
#             'comparison_model': 'bradley_terry_loss'
#         },
#         loss_weights=weights,
#         metrics={
#             'rating_model': 'rating_rmse',
#             'comparison_model': 'custom_binary_accuracy'
#         }
#     )
    
#     # Train the model with early stopping
#     history = joint_model.fit(
#         train_generator,
#         validation_data=val_generator,
#         epochs=epochs,  # Set a high number of epochs to see early stopping in action
#         callbacks=[early_stopping]
#     )
    
#     # Evaluate the model
#     evaluation = joint_model.evaluate(val_generator, verbose=0)
    
#     # Unpack the evaluation results
#     val_loss = evaluation[0]
#     val_rating_model_loss = evaluation[1]
#     val_comparison_model_loss = evaluation[2]


#       # Track number of epochs
#     num_epochs = len(history.history['loss'])
    
#     print(f"weights: {weights}, Validation Loss: {val_loss:.4f}, "
#           f"Validation Rating Model Loss: {val_rating_model_loss:.4f}, "
#           f"Validation Comparison Model Loss: {val_comparison_model_loss:.4f}, "
#           f"Epochs: {num_epochs}")

#     # # Unpack the evaluation results
#     # val_loss = evaluation[0]
#     # rating_rmse = evaluation[1]
#     # comparison_accuracy = evaluation[2]
        

#     # Check for the best val_loss
#     if val_loss < best_val_loss:
#         best_val_loss = val_loss
#         best_weights_val_loss = weights
#         best_epochs_val_loss = num_epochs
    
#     # Check for the best val_rating_model_loss
#     if val_rating_model_loss < best_val_rating_model_loss:
#         best_val_rating_model_loss = val_rating_model_loss
#         best_weights_val_rating_model_loss = weights
#         best_epochs_val_rating_model_loss = num_epochs
    
#     # Check for the best val_comparison_model_loss
#     if val_comparison_model_loss < best_val_comparison_model_loss:
#         best_val_comparison_model_loss = val_comparison_model_loss
#         best_weights_val_comparison_model_loss = weights
#         best_epochs_val_comparison_model_loss = num_epochs
    
#     # Store the results
#     results.append({
#         'weights': weights,
#         'val_loss': val_loss,
#         'val_rating_model_loss': val_rating_model_loss,
#         'val_comparison_model_loss': val_comparison_model_loss,
#         'epochs': num_epochs
#     })

# # Print the best results
# print(f"Best weights for lowest Validation Loss: {best_weights_val_loss}, "
#       f"Validation Loss: {best_val_loss:.4f}, Epochs: {best_epochs_val_loss}")

# print(f"Best weights for lowest Validation Rating Model Loss: {best_weights_val_rating_model_loss}, "
#       f"Validation Rating Model Loss: {best_val_rating_model_loss:.4f}, Epochs: {best_epochs_val_rating_model_loss}")

# print(f"Best weights for lowest Validation Comparison Model Loss: {best_weights_val_comparison_model_loss}, "
#       f"Validation Comparison Model Loss: {best_val_comparison_model_loss:.4f}, Epochs: {best_epochs_val_comparison_model_loss}")





-----------------------------------------------DATA GENERATORS FOR EACH TASK-----------------------------------------------


# # Define the Data Generators for each task
# class RatingDataGenerator(tf.keras.utils.Sequence):
#     def __init__(self, X, y, batch_size, normalize=True):
#         self.X = X
#         self.y = y
#         self.batch_size = batch_size
#         self.normalize = normalize
#         self.indexes = np.arange(len(self.X))
#         self.on_epoch_end()
        
#     def __len__(self):
#         return int(np.floor(len(self.X) / self.batch_size))

#     def __getitem__(self, index):
#         batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
#         X_batch = self.X[batch_indexes]
#         y_batch = self.y[batch_indexes]
        
#         if self.normalize:
#             X_batch = self.normalize_images(X_batch)
        
#         return X_batch, y_batch
    
#     def on_epoch_end(self):
#         np.random.shuffle(self.indexes)
    
#     def normalize_images(self, images):
#         return images / 255.0

# class ComparisonDataGenerator(tf.keras.utils.Sequence):
#     def __init__(self, X_pairs, y_pairs, batch_size, normalize=True):
#         self.X_pairs = X_pairs
#         self.y_pairs = y_pairs
#         self.batch_size = batch_size
#         self.normalize = normalize
#         self.indexes = np.arange(len(self.X_pairs))
#         self.on_epoch_end()
        
#     def __len__(self):
#         return int(np.floor(len(self.X_pairs) / self.batch_size))

#     def __getitem__(self, index):
#         batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
#         X_pairs_batch = [self.X_pairs[k] for k in batch_indexes]
#         y_pairs_batch = self.y_pairs[batch_indexes]
        
#         comparison_input_a = np.array([pair[0] for pair in X_pairs_batch])
#         comparison_input_b = np.array([pair[1] for pair in X_pairs_batch])
        
#         if self.normalize:
#             comparison_input_a = self.normalize_images(comparison_input_a)
#             comparison_input_b = self.normalize_images(comparison_input_b)
        
#         return [comparison_input_a, comparison_input_b], y_pairs_batch
    
#     def on_epoch_end(self):
#         np.random.shuffle(self.indexes)
    
#     def normalize_images(self, images):
#         return images / 255.0

# # Define the combined generator with reinitialization logic
# class CombinedDataGenerator(tf.keras.utils.Sequence):
#     def __init__(self, rating_gen, comparison_gen, rating_batch_size, comparison_batch_size):
#         self.rating_gen = rating_gen
#         self.comparison_gen = comparison_gen
#         self.rating_batch_size = rating_batch_size
#         self.comparison_batch_size = comparison_batch_size
#         self.rating_iter = iter(self.rating_gen)
#         self.comparison_iter = iter(self.comparison_gen)
        
#     def __len__(self):
#         # return min(len(self.rating_gen), len(self.comparison_gen))
#         return max(len(self.rating_gen), len(self.comparison_gen))


#     def __getitem__(self, index):
#         try:
#             rating_data, rating_labels = next(self.rating_iter)
#         except StopIteration:
#             self.rating_iter = iter(self.rating_gen)
#             rating_data, rating_labels = next(self.rating_iter)
        
#         try:
#             comparison_data, comparison_labels = next(self.comparison_iter)
#         except StopIteration:
#             self.comparison_iter = iter(self.comparison_gen)
#             comparison_data, comparison_labels = next(self.comparison_iter)
        
#         return [rating_data, comparison_data[0], comparison_data[1]], [rating_labels, comparison_labels]
    
#     def on_epoch_end(self):
#         self.rating_gen.on_epoch_end()
#         self.comparison_gen.on_epoch_end()
#         self.rating_iter = iter(self.rating_gen)
#         self.comparison_iter = iter(self.comparison_gen)

# # Create data generators for each task
# rating_batch_size = 32
# comparison_batch_size = 64  # Larger batch size for the comparison task

# rating_gen_train = RatingDataGenerator(X_train, y_train, rating_batch_size)
# comparison_gen_train = ComparisonDataGenerator(X_pairs_train, y_pairs_train, comparison_batch_size)
# rating_gen_val = RatingDataGenerator(X_val, y_val, rating_batch_size)
# comparison_gen_val = ComparisonDataGenerator(X_pairs_val, y_pairs_val, comparison_batch_size)

# # Create the combined generators for training and validation
# train_generator = CombinedDataGenerator(rating_gen_train, comparison_gen_train, rating_batch_size, comparison_batch_size)
# val_generator = CombinedDataGenerator(rating_gen_val, comparison_gen_val, rating_batch_size, comparison_batch_size)